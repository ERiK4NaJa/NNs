{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Intro_to_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HurleyJames/GoogleColabExercise/blob/master/Intro_to_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuZDvxoMNCXS",
        "colab_type": "text"
      },
      "source": [
        "## **COMP5623 Artificial Intelligence**\n",
        "University of Leeds\n",
        "Spring 2019-2020\n",
        "\n",
        "\n",
        "The purpose of this notebook is to give you a general understanding of how to use the PyTorch Python package for writing, training and analysing neural networks. Only the key topics are covered, and many references are included to documentation and other helpful resources.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Introduction to PyTorch**\n",
        "\n",
        "\n",
        "Why PyTorch in this module instead of TensorFlow, Keras, Theano, etc.?\n",
        "\n",
        "- Simplicity but not oversimplified\n",
        "- API\n",
        "- Performance\n",
        "\n",
        "![why_pytorch.png](https://drive.google.com/uc?id=1EQqmbiKtXFVTcqGsxnIu_hqVy7vV1Lyp)\n",
        "\n",
        "Some real evidence that researchers are moving steadily towards PyTorch:\n",
        "\n",
        "https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Some recommended resources\n",
        "\n",
        "- Pytorch 60-min Blitz Tutorial https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html\n",
        "- PyTorch Deep Learning Hands-On by Sherin Thomas and Sudhanshu Passi\n",
        "- Stanford Spring 2019 CS231n Convolutional Neural Networks for Visual Recognition http://cs231n.stanford.edu/, particularly Lecture 6 on PyTorch.\n",
        "- \"A Beginner-Friendly Guide to PyTorch and How it Works from Scratch\" https://www.analyticsvidhya.com/blog/2019/09/introduction-to-pytorch-from-scratch/\n",
        "- The “Image classification (MNIST) using Convnets” example from the PyTorch Git repository (https://github.com/pytorch/examples)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "As an overview, this notebook covers:\n",
        "\n",
        "1. Tensors\n",
        "2. Gradients\n",
        "3. Datasets\n",
        "4. Neural networks\n",
        "5. Training (+ training on a GPU)\n",
        "\n",
        "\n",
        "***Welcome to come to lab to work through this notebook and ask questions!***\n",
        "\n",
        "---\n",
        "\n",
        "### 1. Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6-zcPdENCXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C51jrpYNCXZ",
        "colab_type": "text"
      },
      "source": [
        "A Tensor - the basic building block. Similar to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5SdlMccNCXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([5.0, 3, 6.6, 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnvoFZKhNCXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bad_SGELNCXi",
        "colab_type": "text"
      },
      "source": [
        "NumPy-like behaviour for array operations - not a regular Python list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiLAaev1NCXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB9hupOONCXm",
        "colab_type": "text"
      },
      "source": [
        "PyTorch tensors can be on your CPU or GPU. You can explicitly copy it back and forth.  We will look into this more later in this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53NXGS7XNCXn",
        "colab_type": "text"
      },
      "source": [
        "### 2. Gradients\n",
        "\n",
        "PyTorch tensors are more powerful than NumPy ndarrays when we are interested in propagating gradients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPSziGahNCXo",
        "colab_type": "text"
      },
      "source": [
        "Neural networks are trained via two operations:\n",
        "\n",
        "- a forward pass\n",
        "- a backward pass\n",
        "\n",
        "Both the gradient, and forward and backward pass functions are attached to PyTorch's Tensor object.\n",
        "\n",
        "![gradients](https://drive.google.com/uc?id=1bJavTiS98fioAN4ipI82o_Mej4CTI23_)\n",
        "\n",
        "Slide 51, Backpropagation of Gradients, Lecture \"Image Classification using CNNs\"\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Setting **require_grad=True** makes PyTorch track all the operations on that Tensor. When you finish the computation, you can call .backward() on it and the gradients are stored in the **.grad** attribute.\n",
        "\n",
        "- https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html\n",
        "https://towardsdatascience.com/\n",
        "\n",
        "- https://towardsdatascience.com/getting-started-with-pytorch-part-1-understanding-how-automatic-differentiation-works-5008282073ec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ttuc2O7_NCXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor([4.0, 5.0, 6.0], requires_grad=True)\n",
        "x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cefE-tNOajiJ",
        "colab_type": "text"
      },
      "source": [
        "Does **x** have a grad_fn?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ddij89zlal9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.grad_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElaxL3rtNCXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = x + 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpVFdgplaoih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lzsn-dHJNCXx",
        "colab_type": "text"
      },
      "source": [
        "To illustrate how powerful this can be, let's look at the computational graph from the example above. \n",
        "\n",
        "Consider first what this would look like in NumPy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1uUN35zNCXy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([1.0, 2.0, 3.0])\n",
        "w = np.array([4.0, 5.0, 6.0])\n",
        "v = np.array([7.0, 8.0, 9.0])\n",
        "\n",
        "y = x * w"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6VQL9WPNCX8",
        "colab_type": "text"
      },
      "source": [
        "We could compute the gradient for **w** manually using NumPy.\n",
        "\n",
        "![loss](https://drive.google.com/uc?id=1eFM0lRxRlbWXGgB5-0lU-SgUIAT08uny)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGDoUbciNCX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grad_w = v * w\n",
        "\n",
        "print(\"grad_w:\", grad_w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLEVHuomNCYA",
        "colab_type": "text"
      },
      "source": [
        "Now, build the same computational graph in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNGHDDVoNCYA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = torch.tensor((1.0,2.0,3.0), requires_grad=True)\n",
        "x = torch.tensor((4.0,5.0,6.0))\n",
        "v = torch.tensor((7.0,8.0,9.0))\n",
        "\n",
        "y = w * x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oazbMokMXDb-",
        "colab_type": "text"
      },
      "source": [
        "Now, with one function call on the output tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4igAW3ByNCYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.backward(v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibIb8JifNCYF",
        "colab_type": "text"
      },
      "source": [
        "Now we can directly access the gradient on w, which has been calculated for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djMwnFqqNCYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yriVb3QrNCYL",
        "colab_type": "text"
      },
      "source": [
        "If you don't want to track gradients, you can put code inside a **with torch.no_grad()** block. This saves memory. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtuIbtJSNCYM",
        "colab_type": "text"
      },
      "source": [
        "### 3. Datasets\n",
        "\n",
        "We will only cover this briefly, as this code will be provided for you for the coursework dataset. It is helpful to know generally how it works.\n",
        "\n",
        "**Transforms** are common image transformations which can be chained together using Compose().\n",
        "\n",
        "https://pytorch.org/docs/stable/torchvision/transforms.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zm3zlsBWRWH2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzND3DXhNCYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWtHP1q-NCYT",
        "colab_type": "text"
      },
      "source": [
        "Certain commonly-used public datasets are available directly via PyTorch, through **torchvision.datasets**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DhlOV2ANCYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5rJd9vMNCYX",
        "colab_type": "text"
      },
      "source": [
        "Listing of all available datasets here: https://pytorch.org/docs/stable/torchvision/datasets.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3koTaOJNCYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the datasets from PyTorch\n",
        "train_set = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_set = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_teqQ2OBNCYd",
        "colab_type": "text"
      },
      "source": [
        "If you are using a dataset not listed, you can create a custom Dataset class which will inherit the PyTorch parent Dataset class. It can then be loaded the same way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk6kzSlTNCYf",
        "colab_type": "text"
      },
      "source": [
        "Data loaders are provided by **torch.utils.data** and help for easy iteration over datasets. \n",
        "\n",
        "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfFcsImqNCYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=24, # Forward pass only so batch size can be larger\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "classes = np.arange(0, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xd4GKasNCYi",
        "colab_type": "text"
      },
      "source": [
        "To iterate over the test set, one batch at a time, we do the following:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BOyw1HQANCYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 24 images at a time\n",
        "for i, data in enumerate(test_loader, 0):\n",
        "    images, labels = data\n",
        "    print(\"Batch\", i, \"size:\", len(images))\n",
        "    \n",
        "    # Do stuff with the images and labels.\n",
        "    break # Terrible programming. Just for illustration."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRHG-ADrNCYm",
        "colab_type": "text"
      },
      "source": [
        "Note that the length of a loader is the *number of batches*, not the total number of images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l61vr7HANCYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFl1UKe4NCYq",
        "colab_type": "text"
      },
      "source": [
        "If you want to look at the images in the set one by one, you can define a loader with batch_size of 1 and iterate over it using an iterator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ram2KLh0NCYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extra_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "iterator = iter(extra_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiWYqK9YNCYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# iterator.next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv39kevINCYx",
        "colab_type": "text"
      },
      "source": [
        "### 4. Neural networks\n",
        "\n",
        "There are two steps:\n",
        "\n",
        "1. Define the network.\n",
        "2. Specify a loss function and optimizer.\n",
        "\n",
        "First, we recommend defining the network as a class. The **nn** or Neural Network part of PyTorch contains all the classes and functions related to defining a neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU997161NCYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNKjJtQcNCY2",
        "colab_type": "text"
      },
      "source": [
        "Let's build a simple linear classifier.\n",
        "\n",
        "All networks should inherit from the **nn.Module** parent class: https://pytorch.org/docs/stable/nn.html#module\n",
        "\n",
        "**nn.Module** stores learnable weights and state.\n",
        "\n",
        "You will always need two functions:\n",
        "\n",
        "1. __init__, which will be called the moment you instantiate the class.\n",
        "\n",
        "2. **forward()** function which will be called during training.\n",
        "\n",
        "The documentation for all the nn.Module layers supported by PyTorch is here https://pytorch.org/docs/stable/nn.html, including:\n",
        "\n",
        "- Conv2D\n",
        "- MaxPool2D\n",
        "- ReLU\n",
        "- Dropout2D\n",
        "- many, many more.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeXFwo_NNCY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LinearClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_classes=10):\n",
        "        # Calls __init__() on the parent class, which is nn.Module\n",
        "        super(LinearClassifier, self).__init__()\n",
        "        \n",
        "        # Define each layer of the network as a class variable\n",
        "        # fc1 stands for first fully-connected layer\n",
        "        self.fc1 = nn.Linear(28 * 28, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = x.reshape(x.size(0), -1) # TODO what does this do? Why do we need it?\n",
        "        out = self.fc1(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzEDnstBW8cM",
        "colab_type": "text"
      },
      "source": [
        "You can optionally seed the Random Number Generator across all devices for testing purposes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaNZ5hzdXHly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK82t7xsNCY5",
        "colab_type": "text"
      },
      "source": [
        "We can now create a classifier instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c8chSInNCY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LinearClassifier()\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XGVFLV_NCZA",
        "colab_type": "text"
      },
      "source": [
        "The layers can be accessed directly and so can their parameters!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6t708i3NCZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fc1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYXIDYrZXl0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fc1.weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0ULZhy7NCZF",
        "colab_type": "text"
      },
      "source": [
        "Now define the loss and optimiser.\n",
        "\n",
        "\n",
        "- Optimisers https://pytorch.org/docs/stable/optim.html\n",
        "- Loss functions https://pytorch.org/docs/stable/nn.html#loss-functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Tl2gtwrRzbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUv3eFyZNCZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Stochastic gradient descent\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4drUKnKUNCZN",
        "colab_type": "text"
      },
      "source": [
        "### 5. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZKUwo9GNCZO",
        "colab_type": "text"
      },
      "source": [
        "During training, we iterate over a fixed number of epochs. An epoch is *one complete iteration through the entire training set.* \n",
        "\n",
        "You can either fix the number of epochs to train for, or can dynamically determine when to stop training. Alternately, you can checkpoint frequently over a large fixed number of epochs and then determine the best model later. \n",
        "\n",
        "It is highly advised to use a validation set (not shown here)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeT50Y6vNCZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import timeit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bebl4o0eNCZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model_epochs(num_epochs):\n",
        "    \"\"\" Trains the model for a given number of epochs on the training set. \"\"\"\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            images, labels = data\n",
        "\n",
        "            # Zero the parameter gradients means to reset them from\n",
        "            # any previous values. By default, gradients accumulate!\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Passing inputs to the model calls the forward() function of\n",
        "            # the Module class, and the outputs value contains the return value\n",
        "            # of forward()\n",
        "            outputs = model(images)\n",
        "\n",
        "            # Compute the loss based on the true labels\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backpropagate the error with respect to the loss\n",
        "            loss.backward()\n",
        "\n",
        "            # Updates the parameters based on current gradients and update rule;\n",
        "            # in this case, defined by SGD()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Print our loss\n",
        "            running_loss += loss.item()\n",
        "            if i % 1000 == 999:    # print every 1000 mini-batches\n",
        "                print('Epoch / Batch [%d / %d] - Loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 1000))\n",
        "                running_loss = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOQvKBUWNCZX",
        "colab_type": "text"
      },
      "source": [
        "Train and time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T5iAlujNCZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_model_epochs(num_epochs)\n",
        "\n",
        "cpu_train_time = timeit.timeit(\n",
        "    \"train_model_epochs(num_epochs)\",\n",
        "    setup=\"num_epochs=6\",\n",
        "    number=1,\n",
        "    globals=globals(),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsug7r1wNCZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cpu_train_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE_n0h8rNCZg",
        "colab_type": "text"
      },
      "source": [
        "How does the classifier perform on the test set?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4mUuwllNCZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Why don't we need gradients? What happens if we do include gradients?\n",
        "with torch.no_grad():\n",
        "    \n",
        "    # Iterate over the test set\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        \n",
        "        outputs = model(images)\n",
        "        \n",
        "        # torch.max is an argmax operation\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        \n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Coz8pxUANCZj",
        "colab_type": "text"
      },
      "source": [
        "You can save and reload models. Torch models are checkpoint files.\n",
        "\n",
        "https://pytorch.org/tutorials/beginner/saving_loading_models.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZlfdUZTNCZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model, './my_mnist_model.pt') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7EJ12-hNCZq",
        "colab_type": "text"
      },
      "source": [
        "Accuracy and confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m7qvfYnNCZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp872eJeNCZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = confusion_matrix(labels, predicted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9_DcVx_NCZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzAO6TKKNCZ7",
        "colab_type": "text"
      },
      "source": [
        "Let's make it easier for viewing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KV8zssFoNCZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm,\n",
        "                          classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix very prettily.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "\n",
        "    # Specify the tick marks and axis text\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    # The data formatting\n",
        "    fmt = '.2f' if normalize else 'd't\n",
        "    thresh = cm.max() / 2.\n",
        "    \n",
        "    # Print the text of the matrix, adjusting text colour for display\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytZnFKgZNCaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_confusion_matrix(cm, classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYdbep8GNCaF",
        "colab_type": "text"
      },
      "source": [
        "### 5b (optional) Training on a GPU\n",
        "\n",
        "One of the main advantages that Tensors have over NumPy arrays, and which make them so powerful, is that they can be easily moved to a GPU.\n",
        "\n",
        "Why GPU?\n",
        "\n",
        "- many cores = faster at parallel tasks\n",
        "- CPU vs GPU benchmarks training a CNN https://github.com/jcjohnson/cnn-benchmarks\n",
        "\n",
        "Where's the data?\n",
        "Where's the model?\n",
        "Where does the data go when you train the model?\n",
        "\n",
        "![computer.png](https://drive.google.com/uc?id=11uBHkC5tznLhNIGAn0mrggSC2LMEXlYC)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acW0dypgNCaG",
        "colab_type": "text"
      },
      "source": [
        "First get PyTorch to find the device available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTJsIcvbNCaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Device configuration - defaults to CPU unless GPU is available on device\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKsjBcL-NCaJ",
        "colab_type": "text"
      },
      "source": [
        "How do we put the **model** on the GPU?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMQzKKe4NCaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_gpu = LinearClassifier().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zJYcHCfNCaQ",
        "colab_type": "text"
      },
      "source": [
        "How do we put the **data** on the GPU? (Below code is a copy of the training code above, just simplified without comments and loss printing.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fq3hndyNCaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model_epochs2(num_epochs):\n",
        "    \"\"\" Copy of function train_model_epochs but explicitly copying data to device \n",
        "        during training. \n",
        "    \"\"\"\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            images, labels = data\n",
        "\n",
        "            # Explicitly specifies that data is to be copied onto the device!\n",
        "            images = images.to(device)  # <----------- And note it's NOT an in-place operation; original\n",
        "            labels = labels.to(device)  # <----------- variables still exist on CPU\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model_gpu(images)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            if i % 1000 == 999:    # print every 1000 mini-batches\n",
        "                print('Epoch / Batch [%d / %d] - Loss: %.3f' %\n",
        "                      (epoch + 1, i + 1, running_loss / 1000))\n",
        "                running_loss = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ4fN7UKcsQS",
        "colab_type": "text"
      },
      "source": [
        "Train an identical second model on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UyKM5Z9NCaU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# gpu_train_time = timeit.timeit(\n",
        "#     \"train_model_epochs2(num_epochs)\",\n",
        "#     setup=\"num_epochs=6\",\n",
        "#     number=1,\n",
        "#     globals=globals(),\n",
        "# )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c19bEzAIX3Vq",
        "colab_type": "text"
      },
      "source": [
        "Feel free to compare **cpu_train_time** with **gpu_train_time**, keeping in mind that an inappropriate batch size may give you surprising results! Remember that copying data to the GPU also has an overhead.\n",
        "\n",
        "For those curious about optimisation on a GPU, NVidia's article on [NVidia's Deep Learning Performance Guide](https://docs.nvidia.com/deeplearning/sdk/dl-performance-guide/index.html) is helpful."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbdD8W2YVpSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ve5aTtfXWKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}